# Description: super-small and empty BareMetalHostProfile
# which supposed to be used only in test-envs or for PoC
apiVersion: metal3.io/v1alpha1
kind: BareMetalHostProfile
metadata:
  namespace: child
  name: ceph
  labels:
    kaas.mirantis.com/provider: baremetal
    kaas.mirantis.com/region: region-one
spec:
  devices:
    # First found disk, for base system
    - device:
        #byName: /dev/sda
        minSizeGiB: 60
        wipe: true
      partitions:
          # Those name is mandatory!
        - name: bios_grub
          # 4Mb. Required for non-uefi systems
          sizeGiB: 0.00390625
          partflags: ['bios_grub']
          wipe: true
        - name: uefi
          partflags: ['esp']
          sizeGiB: 0.2
          wipe: true
        - name: config-2
          # limited to 64Mb
          sizeGiB: 0.0625
          wipe: true
        - name: lvm_root_part
          wipe: true
          # Means, all left space
          sizeGiB: 0
    # Second disk, for local-volume-provisioner mounts. See clusterreleases.kaas.mirantis.com objects also
    - device:
        #byName: /dev/sdb
        minSizeGiB: 30
        wipe: true
      partitions:
        - name: lvm_lvp_part
          wipe: true
          # Means, all left space
          sizeGiB: 0
    # Third disk, for ceph storage. See kaascephcluster.yaml.template also
    - device:
        #byName: /dev/sdc
        minSizeGiB: 30
        wipe: true
    - device:
        #byName: /dev/sdd
        minSizeGiB: 30
        wipe: true
    - device:
        #byName: /dev/sde
        minSizeGiB: 30
        wipe: true
  volumeGroups:
    - name: lvm_root
      devices:
        - partition: lvm_root_part
    - name: lvm_lvp
      devices:
        - partition: lvm_lvp_part
  logicalVolumes:
    - name: root
      vg: lvm_root
      # Means, all left space
      sizeGiB: 0
    - name: lvp
      vg: lvm_lvp
      # Means, all left space
      sizeGiB: 0
  fileSystems:
    - fileSystem: vfat
      partition: config-2
    - fileSystem: vfat
      partition: uefi
      mountPoint: /boot/efi
    - fileSystem: ext4
      logicalVolume: root
      mountPoint: /
    - fileSystem: ext4
      logicalVolume: lvp
      mountPoint: /mnt/local-volumes/
  preDeployScript: |
    #!/bin/bash -ex
    echo $(date) 'pre_deploy_script done' >> /root/pre_deploy_done
  postDeployScript: |
    #!/bin/bash -ex
    echo $(date) 'post_deploy_script done' >> /root/pre_deploy_done
  grubConfig:
    defaultGrubOptions:
      - 'GRUB_DISABLE_RECOVERY="true"'
      - 'GRUB_PRELOAD_MODULES=lvm'
      - 'GRUB_TIMEOUT=20'
  kernelParameters:
    sysctl:
      # reboot machine after kernel panic. 15m*60
      kernel.panic: "900"
      # restrict kernel logs to root only
      kernel.dmesg_restrict: "1"
      # controls whether core dumps will append the PID to the core filename
      # useful for debugging multi-threaded applications
      kernel.core_uses_pid: "1"
      # increase system file descriptor limit
      # this value can be up to:
      #   - 9223372036854775807 (0x7fffffffffffffff) on a 64-bit system
      # be aware that the Linux kernel documentation suggests that inode-max should be 3-4 times
      #   larger than this value
      fs.file-max: "9223372036854775807"
      # The Linux kernel provides the Asynchronous non-blocking I/O (AIO) feature that allows a
      # process to initiate multiple I/O operations simultaneously without having to wait for any of them to complete.
      # This helps boost performance for applications that are able to overlap processing and I/O.
      fs.aio-max-nr: "1048576"
      # The inotify API provides a mechanism for monitoring file system events.
      # Inotify can be used to monitor individual files, or to monitor directories.
      # When a directory is monitored, inotify will return events for the directory itself, and for files inside the directory.
      fs.inotify.max_user_instances: "4096"
      #This file contains the maximum number of memory map areas a process may have.
      # Memory map areas are used as a side-effect of calling malloc, directly by mmap and mprotect, and also when loading shared libraries.
      # While most applications need less than a thousand maps, certain programs,
      # particularly malloc debuggers, may consume lots of them, e.g., up to one or two maps per allocation.
      vm.max_map_count: "262144"
